# -*- coding: utf-8 -*-
"""Analysis1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1siN6MnLWF5j8M13jRek_HKX3ynqr24ZZ
"""

from google.colab import drive

drive.mount('/content/drive')

!mkdir -p "/content/drive/MyDrive/Stock_Analysis/data/raw"
!mkdir -p "/content/drive/MyDrive/Stock_Analysis/data/processed"
!mkdir -p "/content/drive/MyDrive/Stock_Analysis/scripts"
!mkdir -p "/content/drive/MyDrive/Stock_Analysis/data/raw/fundamentals"
!mkdir -p "/content/drive/MyDrive/Stock_Analysis/plots"

!pip install yfinance pandas-datareader --quiet

hypotheses = '''
   H0: Fundamentals explain >50% of return variance in all conditions.
   H1: External flows dominate (>50% variance) in low-volatility regimes.
   H2: Fundamentals and flows decouple during Fed policy shifts.
   '''

with open('/content/drive/MyDrive/Stock_Analysis/data/hypotheses.txt', 'w') as f:f.write(hypotheses)

sp500_tickers = ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'TSLA']
russell_tickers = ['ANF', 'DECK', 'SM', 'AMN', 'AAP']
all_tickers = sp500_tickers + russell_tickers

import yfinance as yf
import pandas as pd


data = yf.download(
    all_tickers,
    start='2000-01-01',
    end='2023-12-31',
    interval='1mo',
    group_by='ticker'
)

print(data)

data.to_csv('/content/drive/MyDrive/Stock_Analysis/data/raw/stock_data.csv')

prices = {}
for ticker in all_tickers:

    df = data[ticker].copy()
    prices[ticker] = df['Close']

prices_df = pd.DataFrame(prices)
returns_df = prices_df.pct_change().dropna()


returns_df.to_csv('/content/drive/MyDrive/Stock_Analysis/data/processed/monthly_returns.csv')

import yfinance as yf


tickers = ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'TSLA', 'ANF', 'DECK', 'SM', 'AMN', 'AAP']


for ticker in tickers:
    stock = yf.Ticker(ticker)


    income_stmt = stock.financials.T  # Income Statement
    balance_sheet = stock.balance_sheet.T  # Balance Sheet
    cash_flow = stock.cashflow.T  # Cash Flow Statement


    income_stmt.to_csv(f"/content/drive/MyDrive/Stock_Analysis/data/raw/fundamentals/{ticker}_income_statement.csv")
    balance_sheet.to_csv(f"/content/drive/MyDrive/Stock_Analysis/data/raw/fundamentals/{ticker}_balance_sheet.csv")
    cash_flow.to_csv(f"/content/drive/MyDrive/Stock_Analysis/data/raw/fundamentals/{ticker}_cash_flow.csv")

import os
import pandas as pd

def process_income_statement(ticker):
    file_path = f'/content/drive/MyDrive/Stock_Analysis/data/raw/fundamentals/{ticker}_income_statement.csv'
    if os.path.exists(file_path):

        df = pd.read_csv(file_path, parse_dates=True, index_col=0)


        if "Total Revenue" in df.columns and "Net Income" in df.columns:

            df_processed = df[['Total Revenue', 'Net Income']].copy()
            df_processed.rename(columns={"Total Revenue": "Revenue", "Net Income": "EPS"}, inplace=True)

            df_processed.index = pd.to_datetime(df_processed.index)
            df_monthly = df_processed.resample('M').ffill()

            out_path = f'/content/drive/MyDrive/Stock_Analysis/data/processed/fundamentals_{ticker}.csv'
            df_monthly.to_csv(out_path)
            print(f"Processed fundamentals for {ticker} saved to {out_path}")
        else:
            print(f"Required columns not found for {ticker}. Found: {df.columns.tolist()}")
    else:
        print(f"File not found for {ticker} at {file_path}")

for ticker in ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'TSLA']:
    process_income_statement(ticker)

!pip install pandas_datareader

from pandas_datareader import data as pdr

vix = pdr.get_data_fred('VIXCLS', start='2000-01-01', end='2023-12-31')
vix_monthly = vix.resample('M').mean()
vix_monthly.to_csv('/content/drive/MyDrive/Stock_Analysis/data/processed/monthly_vix.csv')

for ticker in ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'TSLA']:

    ret = returns_df[ticker].copy()
    ret.index = pd.to_datetime(ret.index)

    fundamentals_path = f'/content/drive/MyDrive/Stock_Analysis/data/processed/fundamentals_{ticker}.csv'
    try:
        fund = pd.read_csv(fundamentals_path, index_col=0, parse_dates=True)
    except Exception as e:
        print(f"Error loading fundamentals for {ticker}: {e}")
        continue

    fund = fund.reindex(ret.index, method='ffill')

    vix_data = pd.read_csv('/content/drive/MyDrive/Stock_Analysis/data/processed/monthly_vix.csv', index_col=0, parse_dates=True)
    vix_data = vix_data.reindex(ret.index, method='ffill')

    df = pd.DataFrame({'Return': ret})
    df = df.join(fund, how='left')
    df = df.join(vix_data, how='left')

    if 'VIXCLS' in df.columns:
        df.rename(columns={'VIXCLS': 'VIX'}, inplace=True)

    df.dropna(inplace=True)

    out_file = f'/content/drive/MyDrive/Stock_Analysis/data/processed/data_{ticker}.csv'
    df.to_csv(out_file)

import numpy as np
from scipy.stats import mstats

def winsorize_series(s, limits=[0.01, 0.01]):
    if s.empty:
        return s
    return mstats.winsorize(s, limits=limits)

for ticker in ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'TSLA']:
    file_path = f'/content/drive/MyDrive/Stock_Analysis/data/processed/data_{ticker}.csv'
    df = pd.read_csv(file_path, index_col=0, parse_dates=True)

    if df.empty:
        print(f"No data for {ticker}. Skipping winsorization.")
        continue

    #winsorization
    for col in ['Return', 'EPS', 'Revenue', 'VIX']:
        if col in df.columns:
            if df[col].empty:
                print(f"Column {col} is empty for {ticker}. Skipping winsorization for this column.")
            else:
                df[col] = winsorize_series(df[col])


    df.to_csv(file_path)
    print(f"Cleaned data for {ticker} saved.")

import statsmodels.api as sm

results = {}

for ticker in ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'TSLA']:
    file_path = f'/content/drive/MyDrive/Stock_Analysis/data/processed/data_{ticker}.csv'
    df = pd.read_csv(file_path, index_col=0, parse_dates=True)


    if 'Volume' in df.columns:
        X_full = sm.add_constant(df[['EPS', 'Revenue', 'Volume', 'VIX']])
        X_flow = sm.add_constant(df[['Volume', 'VIX']])
    else:
        X_full = sm.add_constant(df[['EPS', 'Revenue', 'VIX']])
        X_flow = sm.add_constant(df[['VIX']])

    X_fund = sm.add_constant(df[['EPS', 'Revenue']])
    y = df['Return']


    full_model = sm.OLS(y, X_full).fit()
    fund_model = sm.OLS(y, X_fund).fit()
    flow_model = sm.OLS(y, X_flow).fit()

    results[ticker] = {
        'R2_full': full_model.rsquared,
        'R2_fund': fund_model.rsquared,
        'R2_flow': flow_model.rsquared
    }

    print(f"Ticker: {ticker}")
    print("Full Model R²:", full_model.rsquared)
    print("Fundamentals Model R²:", fund_model.rsquared)
    print("Flows Model R²:", flow_model.rsquared)
    print("-" * 50)

from statsmodels.tsa.vector_ar.var_model import VAR


aapl_file = '/content/drive/MyDrive/Stock_Analysis/data/processed/data_AAPL.csv'
aapl_df = pd.read_csv(aapl_file, index_col=0, parse_dates=True)


var_data = aapl_df[['Return', 'EPS', 'Revenue', 'VIX']]
var_model = VAR(var_data)
var_results = var_model.fit(maxlags=2)
print(var_results.summary())

!pip install xgboost shap optuna

import xgboost as xgb
import shap
import optuna
from sklearn.model_selection import train_test_split


aapl_df = pd.read_csv('/content/drive/MyDrive/Stock_Analysis/data/processed/data_AAPL.csv', index_col=0, parse_dates=True)


features = aapl_df[['EPS', 'Revenue', 'VIX']]
target = aapl_df['Return']

X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, shuffle=False)

dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)

params = {
    'objective': 'reg:squarederror',
    'eval_metric': 'rmse'
}

model = xgb.train(params, dtrain, num_boost_round=100)
preds = model.predict(dtest)

# SHAP analysis for feature importance
explainer = shap.Explainer(model)
shap_values = explainer(X_test)
shap.summary_plot(shap_values, X_test)

from sklearn.model_selection import TimeSeriesSplit
import numpy as np

tscv = TimeSeriesSplit(n_splits=5)
X = features.values
y = target.values

for train_index, test_index in tscv.split(X):
    X_train_cv, X_test_cv = X[train_index], X[test_index]
    y_train_cv, y_test_cv = y[train_index], y[test_index]
    dtrain_cv = xgb.DMatrix(X_train_cv, label=y_train_cv)
    dtest_cv = xgb.DMatrix(X_test_cv, label=y_test_cv)

    cv_model = xgb.train(params, dtrain_cv, num_boost_round=50)
    preds_cv = cv_model.predict(dtest_cv)
    rmse = np.sqrt(np.mean((y_test_cv - preds_cv)**2))
    print("RMSE for this split:", rmse)

for ticker, res in results.items():
    delta_r2 = res['R2_full'] - res['R2_fund']
    print(f"{ticker}: ΔR² (Flows Impact) = {delta_r2:.2%}")

import matplotlib.pyplot as plt

aapl_df = pd.read_csv('/content/drive/MyDrive/Stock_Analysis/data/processed/data_AAPL.csv', index_col=0, parse_dates=True)
plt.figure(figsize=(8,6))
plt.scatter(aapl_df['VIX'], aapl_df['Return'], alpha=0.5)
plt.xlabel('VIX')
plt.ylabel('AAPL Return')
plt.title('AAPL: Return vs. Market Volatility')
plt.grid(True)
plt.savefig('/content/drive/MyDrive/Stock_Analysis/plots/vix_vs_return.png')
plt.show()

